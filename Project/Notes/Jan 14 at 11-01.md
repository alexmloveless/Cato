This is me, Cato, C-A-T-O. It's a terminal-based language-building channel.
This is actually the third generation of soap to apply.
There's been ancient kind of bits from scratch and evolved.
But I've had to create multiple iterations because over time the additional functionality I've added has been built upon
less than sound, bass, architectural and engineering principles and design decisions
are made during enhancements of a kind of significant technical net to the scale to which we can rebuild it.
I think we're going to try and fix it.
In prior incarnation it was called OCAT, C-A-T, and wherever you see OCAT you should assume, by now I mean Cato,
you will not be given access to the own kind of code base because I want to architect it from first principles.
Don't repeat prior mistakes. OCAT, sorry, TACO, but Cato exists for two reasons.
The first is that I want a chat client so that I can have maximum control over interactions with language models
that I can tailor to my specific needs and build an engineer around the world.
While I own idiosyncrasies I will get into more specific needs shortly.
The second reason is something like an artist's agent opening and the environment of application that is non-volatile,
that other people will not be affected by decisions and any mistakes that I made.
Although Cato code base will be shared on GitHub if people want to look at it and fork it,
however I will not be unlikely to accept change requests and pull requests.
I want to remain as free as possible to create the app that suits me and to be free to make mistakes and discoveries at my own pace, on my own terms,
without having to worry about other people having opinions on it or interfering.
That doesn't mean I'm happy with shitty design decisions, poor architecture, lazy coding etc. This needs to be of the highest standard.
The core of base architecture needs to remain flexible and modular so that any poor design decisions or functionality that I may have deemed necessary can easily be unplugged or switched out.
Woke up, sorry Cato.
There needs to be a client first that doesn't rule out any framework or API engineering, it's just that there's a way to get it secondary to the main function.
We need to maintain separation of logic and display as much as possible so that we can plug in different front ends.
That doesn't mean that it should cater for any possible front end necessarily.
This is first and foremost a terminal application therefore you should only really expect alternative front ends to be using alternative terminal front end paradigms.
We also want to keep things like style configuration etc. where they're appropriate so it should be kept separate unless such style information is very particular
and very specific to a front end paradigm.
The CAD needs to be configurable although it's really being built for a single user case which is me, what you have to understand about me is that I'm ADHD, I'm highly compressive, highly changeable, I like to change things and tinker with things and experiment.
A lot.
Therefore no good with architecture needs to be as flexible and configurable as possible.
I'm less worried about having extensive configuration options than I am.
We should have configuration options for everything that makes sense to configure but make sure that the base configuration is well documented and the options are clear.
Cato will have a headless mode that is necessarily limited.
So for example, the ability to have one shot queries sent to the model based on just from a single command rather than instantiating the whole interface, it should be possible to query, to add and remove things.
From the vector store and any other databases for the command line. However, Cato should be configuration file driven as much as possible.
Configuration should be in YAML with extensive documentation in line for the default configuration files.
There should be no hard coded inline values and the default configuration should be stored in a YAML file.
Rather than as function or method default.
You should use Pydantic extensively to validate infants.
As a general design principle, you should favour the Pydantic stack for API interactions.
The Pydantic language model toolkits rather than stuff like Lang chain which will only use if there is no other way of doing it in the approved architectural stack.
As a general principle, we should err on the side of minimising dependencies on external libraries where one of the existing library dependencies has something that will suffice.
But do not code natively something that already can be done with one of the approved dependencies.
Do not add new dependencies outside of the improved stack without asking me first.
This repository and application will live and die by its functional specification which in its first iteration is a pared down functional specification for the OCAT app.
The functional specification will not be static. It will need to be kept updated at all times and will be the Bible for all future development.
If we make a decision that either adds to or alters the functional specification,
we need to adjust the functional specification and make a note of what we have done and when.
All development, design, architecture decisions need to be kept in a log. All conversations between myself and any model need to be kept in a log.
You should assume that multiple different models from multiple different providers will be used.
You should assume that multiple agents from multiple different providers will be used and any combination of either.
We will keep an architectural and technical specification and set of principles although I am less concerned about the absolute sanctity of this simply because
a lot of that will be handled via intelligent documentation throughout the application.
So for example, any separated modules, especially where they are separated in directories should contain a log file in that directory that explicitly tells any model or developer.
What is going on in there? What can be found and what is used for coitus towards the most common functions or classes or methods and pointers as to how to add to legitimate elements.
For example, you will note a command system. So if I am writing command, it should be absolutely clear very quickly and easily how to add that, exactly what to update, where to add documentation and so on.
But with minimal code scanning by the model or the agent.
I am going to talk about all the most common development tasks with clear pointers as to what documentation to read to do that.
So any model only needs to read agent.txt to be able to quickly navigate and get to exactly the point it needs to get to without having significant code based scanning which will clutter up the context.
Functionally, I don't think there is anything particularly exotic going on here. What this doesn't need to be is an agent. There are plenty of agents out there, I don't need to engineer my agent.
It needs to be a chat client and a productivity client. So a chat client first, a productivity client second. Therefore, it needs to be a bit of a one stop shop for getting things done, researching, maintaining,
long running, conversational themes or threads. So the focus will be maintaining intelligent conversational concepts.
Which may also include the content of, for example, tasks in the task list. So imagine I am writing a podcast episode script about a famous artist.
I could have a to do list or a category in a to do list that contains all those tasks and I should be able to easily retrieve this.
Have it be added to the current conversation context as well as any prior threads that relate to it.
So that I can continue without the model of returning information or asking questions about stuff that has already been discussed.
Now, so in that sense, it's also access and knowledge. Therefore, the structure of the vector store is important.
One thing that Okant failed with is retrieving contextual items from the vector store in real time.
The idea is that if I started talking about how to make cheese, any relevant cheese based threads or items should be automatically added to the context.
At least up to a limit, up to a configured limit.
So if I then go in and go, what do I know about cheese? It will tell me. Or if I go in there and go tell me how to make cheddar, it will contextualize responses based on prior conversations about this.
The system prompt is very important because I would like to be able to tailor the tone and the language used in responses.
I also want to be able to either temporarily or permanently adjust the system prompt via the interface.
Productivity tasks and other productivity actions will always be done via the command interface and therefore should not be added to the context.
Unless explicitly asked to do so.
We experimented with natural language interfaces to the productivity interface, which I found difficult, unreliable, annoying with a bunch of side effects.
Therefore, no natural language interface to the command system is necessary.
There may be some need for agent-like features where natural language can be used to do certain specific and specified tasks.
Therefore, the architecture should be legal for this, but it will not be in the initial fashion or specification.
I need to be able to add information to the vector store and indeed remove information via the client.
This will usually be my way of me attaching a document or a web page or something to the current context.
If instructed, that same document should be added, chunked up and added to the vector store.
Junking strategies are important and should be configurable so that we don't end up stuck to the context with whole conversations that are not all of which is relevant.
Therefore, we store individual exchanges with enough contextual information, i.e. prior exchanges and any metadata that is relevant.
The vector store should be engineered and architected, data architected with retrievability in mind, particularly fuzzy retrievability.
What I found with OCAT is that as the context of the chat gets longer, the less stuff is retrieved from the database.
We perhaps need to consider dynamic thresholding or similarity scores.
Although OCAT is really made for one person, one session, it should at least be robust enough to handle a couple of sessions at once.
This element does not need to be over-engineered, it is highly unlikely that two instances on the same machine are available.
It is also highly unlikely that I will ever require databases or vector stores to be remote.
This should be considered an application that runs a single instance, single machine, single person.
With that said, I may have multiple instances running with different profiles, so there will be a profile which is a copy of the default profile,
which defines how the instance will behave.
Therefore, the application Cato requires a configuration file at runtime, but will fall back to the default configuration.
Thank you.
The in-app help should be pretty extensive.
It is not really necessary to stuff the context with knowledge of how Cato works outside of what is necessary for the model to do its job.
For example, the model does not need to know how the command system works, that is what the help files are for.
The help system needs to be really robust and really kept up to date and easy to navigate so that I do not have to rely on the model.
But there should be a facility that I can run a command that asks the model specifically to help, which will dump all the user help files into the context and then I can have a chat with the model about that.
By default, the system prompt should have the bare minimum needed for the model to do its job. It does not need to be aware of how the user interface works.
Now, there is a user defined system prompt. There will be a default system prompt markdown file or similar that has a very basic bare minimum user system prompt.
It should the user not provide one. Just on configuration, the configuration file need only have one key value pair in it.
And then the app should fall back on all the other defaults. So effectively, the user configuration file overlays the default system file and overrides it, but it is not necessary for it to mirror every single parameter.
Back on system prompt, there will be a master system prompt which provides all the necessary information for the model to do its job to which the user system prompt is added.
So there should be clear sections within the final generated system prompt, which clearly denotes different types of instruction.
So the system prompt may be created using multiple different pieces, but there will always be this master prompt, which is the thing that has the information that the model needs to do its job.
That prompt should be sacrosanct. Any changes to any of the default or master prompts should be treated exactly as code and should only be updated when absolutely necessary.
The chat interface, the default chat interface is clean and clear. High contrast and dyslexia friendly. I am dyslexic. I am also ADHD.
So it should be absolutely clear and easy to read.
One problem I had with OCAT was that it presented responses in neat boxes, which is fine, but it means I cannot copy and paste directly from the terminal without including a whole bunch of unnecessary formatting.
So I do not want to do this, but I do want it to be clear which are the responses and which are my prompts and which are the model's responses.
It should be clear and easy for me to write exchanges or portions of exchanges to files in the file system when I need to end line.
When OCAT boots up, it should start as quickly as possible, all interactions to the database should be in real time. No data caching necessary outside of what is being kept in the context.
When booted up, the welcome message should be focused on key configuration options that might make this different from another session.
So I want to know which profile I am using, where that profile file is, where the system profile is, and which main elements are different from the core configuration, the default configuration.
This does not need to include style, just configuration, default effect, behavioral functionality, so it should be very clear and easy for me to scroll up to the top of the chat and see exactly what is in the profile without having to dig around the file system.
The prompt, the user prompt should be very configurable and be able to include Unicode, emojis and similar, so that it is clear from the prompt which profile I am in.
I can also then adjust style information between profiles if I really need to be clear which one I am working in.
OCAP lives and dies by the vector store. Everything relevant should be kept in there, but we do not need to gunk it up with every piece of configuration used in every thread or session.
We just need to point towards the profile that we see.
Any high level metadata might be relevant, such as the model that created the response.
So basically the user interface should be simple and clean, but I am fine with a rich and extensive command set, but we need to make sure that the inline documentation is extremely clear and easy to navigate and always kept up to date when commands are added or changed.
We should maintain a separate store of vital information.
No scratch there. Any extra info I want to be sent to the model can be sent.
I really dislike inline hard coded values and defaults.
I really dislike broad exception handling, which should be as atomic as possible.
I want extensive debug throughout the entire application stack. I want the debug mode to be really, really chatty.
I do not want to have to dig through and create great points or whatever to diagnose problems. I want the application almost to diagnose itself.
Therefore, a worn mode should be pretty chatty, but only relevant to the user experience. Don't do anything silently.
If you can't write to the database after multiple retries, tell the user. If you can't speak to the model, tell the user, make it clear and expensive.
Assume that the person using it is me. I am an extremely proficient Python software developer. I want to be told when things aren't working properly, don't try and hide it from me.
That said, keep the messages human readable.
I favor catching exceptions over returning error or warning messages directly from Python, certainly.
Understanding what is being sent to the model at any given point in time is important. I am particularly interested in knowing exactly what context was sent through.
There is a command to turn on context monitoring that allows me to see exactly what is being sent to and from the model. This should be enabled by default.
I don't need to know the entire contents of the system prompt unless I explicitly ask for it, but there should be a command that will write the entire system prompt to the client should I need to see it.
That should be exactly the system prompt sent in that session to the model.
Efforts should be made to minimize my need or the models need to go poking around in the code to figure out problems, especially when those problems aren't actually correlated, they might be a problem with configuration.
For example, if I cut a typo, or an unrecognized config item, it shouldn't crash, it should just clearly report to me that you've got an unrecognized config item at runtime.
And then carry on as normal.
At any given point in time, it should be quick, easy, and dependent on very little scanning of the code base at any model or any agent to familiarize yourself with the code base, you should assume no other knowledge.
Everything that any agent needs to do anything needs to be very quickly discoverable. You need to minimize the need for models to scan code or open or even look at any code.
Therefore, modularity in the code and modularity in terms of code files should be enforced as long as it doesn't interfere with the code.
But if there's a common section of code that needs to be frequently updated, for example adding new commands, the system to do that should be as atomic as possible, so minimal code needs to be added.
So consider even an interface where individual commands are added via separate code files, which are then imported.
For core system code, this is less necessary and code an architectural simplicity and robustness of engineering should take precedence.
The modularity of the code base should take care of the simplicity of our base.
The speed at which it runs outside of constraints around later, see if model API access should be absolutely minimized.
Ocat did something really stupid, which was to load the entire vector store into memory at runtime, which was utterly unforgivable. It took ages to the start.
There should be no reason why KTA can't boot up instantaneously.
There is no need for gradual streamed output to the client.
But if there is a long response, time, i.e. the model's doing something, doing a lot of output, there should be a indicator to say it's waiting, rather than just the user hanging.
Text-to-speech interface is important. It should be kept simple and very configurable and have the ability to use multiple models from multiple providers.
There might be a need to include some multi-modal elements, so the architecture should be made immediately to that day.
